---
title: "Competition"
author: 
  - name: Mazie Burt
    email: mazie.burt@snhu.edu
    affiliations: 
      - name: Southern New Hampshire University
format: html
date: 1/13/2025
date-modified: today
date-format: long
theme: flatly 
toc: true
code-fold: true
---

```{r}

#| echo: false
#| message: false
#| warning: false


library(tidyverse)
library(tidymodels)
library(kableExtra)
library(patchwork)
library(dplyr)

options(kable_styling_bootstrap_options = c("hover", "striped"))

theme_set(theme_bw(base_size = 14))

Comp <- read.csv("comp.csv")
Data <- read.csv("data.csv")

set.seed(123)
data_splits <- initial_split(Data, prop = 0.85)

train <- training(data_splits)
test <- testing(data_splits)


```

## Statement of Purpose

I aim to develop a highly accurate predictive model that estimates the list-price range for properties listed on Zillow using a comprehensive data set. This model will incorporate key variables such as property features, school ratings, and location-based factors to enhance prediction accuracy. The resulting predictive model will be valuable to Zillow, real estate professionals, and potential buyers by providing data-driven insights helping them make informed decisions based on market trends and property features.

## Executive Summary

## Introduction

## Exploratory Data Analysis

The original data set on properties on Zillow contained 7498 observations and 16 variables. Below we can see the first six properties and their data.

```{r}
Data |>
  head()
```

This data was then split into training and test data. Below we can see the first six rows of the train data set.

```{r}
train |> 
  head()
```

##Price Range Variable

Our goal is to understand what variables affect the price range of properties listed on Zillow. To begin we will look at the distribution of price ranges for these properties.

```{r}
train |>
ggplot() +
  geom_bar(aes(x = priceRange, fill = priceRange)) +  # Adjust bar wi <- h
  scale_y_continuous(expand = c(0, 0)) +  # Remove extra space above bars
  theme_minimal() +  # Use a cleaner theme
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "none"  # Remove legend if not needed
  ) +
  labs(
    title = "Price Range Distribution",
    x = "Price Range",
    y = "Count"
  )
```

This bar graph shows that about 1500 properties are within the price range 250,000 and 300,000, this price range has the highest number of properties. The second highest number of properties is in the price range 350,000 to 450,000 with just under 1500 properties. Next, the 450,000 to 650,000 price range has just under that of the 350,000 to 450,000 price range. The 650,000+ price range has approximately 1150 properties. Lastly, the 0 to 250,000 price range has just over 750 properties listed on Zillow in this data set.

##City Variable

```{r}
train |>
ggplot() +
  geom_bar(aes(x = city)) +  # Adjust bar width
  scale_y_continuous(expand = c(0, 0)) +  # Remove extra space above bars
  theme_minimal() +  # Use a cleaner theme
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "none"  # Remove legend if not needed
  ) +
  labs(
    title = "City Counts Distribution",
    x = "City",
    y = "Count"
  )
```

This graph shows that most of the properties (\>6000) are located in Austin with very few properties located in other cities.

###City vs. Price Range

```{r}
train |> 
  ggplot() + 
  geom_bar(aes(x = city, fill = priceRange)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "City", y = "Price Range", title = "City vs. Price Range")

```

This bar graph shows that in Austin there are similar amounts of properties within the 250,000 - 350,000, 350,000 - 450,000, and 450,000 - 650,000 price ranges. There are fewer properties 650,000+ and even fewer 0 - 250,000. The other cities have a very small number of properties and it is hard to identify the price ranges of those properties.

##Home Type Variable

```{r}
train |>
ggplot() +
  geom_bar(aes(x = homeType, fill = homeType)) +  # Adjust bar width
  scale_y_continuous(expand = c(0, 0)) +  # Remove extra space above bars
  theme_minimal() +  # Use a cleaner theme
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "none"  # Remove legend if not needed
  ) +
  labs(
    title = "Home Type Counts Distribution",
    x = "Home Type",
    y = "Count"
  )
```

This graph shows that the majority of properties in this data set are single family homes with over 5000 properties. The second most common home type in this data set are condos with about 250 properties.

###Home Type vs. Price Range

```{r}
train |>
ggplot(aes(x = homeType, y = priceRange, fill = as.factor(priceRange))) +
  geom_bar(stat = "identity") + 
  scale_fill_manual(values = c("#F8766D", "#A3A500", "#00BF7D", "#00B0F6", "#E76BF3")) +  # Custom colors
  labs(title = "Home Type vs Price Range", x = "Home Type", y = "Price Range", fill = "Price Range") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Rotate x-axis labels
        axis.text.y = element_text(size = 12),  # Adjust y-axis label size
        plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))  # Center the title

```

Single family homes appear to have similar counts for both 650,000 + and 450,000 - 650,000 price ranges. These two price ranges seem to be the most frequent for single family homes. The count of homes in each price range decreases with the price range.

##Garage Spaces Variable

```{r}
train |>
ggplot() +
  geom_bar(aes(x = garageSpaces, fill = garageSpaces)) +  # Adjust bar width
  
  scale_y_continuous(expand = c(0, 0)) +  # Remove extra space above bars
  theme_minimal() +  # Use a cleaner theme
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "none"  # Remove legend if not needed
  ) +
  labs(
    title = "Gararge Spaces Counts Distribution",
    x = "Garage Spaces",
    y = "Count"
  )
```

The most frequent garage spaces count is zero with almost 3000 properties. Second, two garage spaces has under 2500 properties. Properties with one, three, or four garage spaces had counts under 500. Properties with five or more garage spaces are very few.

###Garage Spaces vs. Price Range

```{r}
train |> 
  ggplot() +
  geom_bar(aes(x = garageSpaces, fill = priceRange)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Garage Spaces", y = "Price Range", title = "Garage Spaces vs. Price Range")
```

For properties with zero garage spaces the price range 250,000 to 350,000 seems to be the most common. For one garage space the price ranges are pretty equal. For two garage spaces properties in the three middle price ranges seem to be equal with less properties in 0 - 250,000 and 650,000 +. Properties with three garage spaces are predominately 450,000 - 650,000 and 650,000+.

##Year Built Variable

```{r}
train |>
ggplot() +
  geom_histogram(aes(x = yearBuilt, fill = yearBuilt)) +  # Adjust bar width
  scale_y_continuous(expand = c(0, 0)) +  # Remove extra space above bars
  theme_minimal() +  # Use a cleaner theme
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "none"  # Remove legend if not needed
  ) +
  labs(
    title = "Year Built Counts Distribution",
    x = "Year Built",
    y = "Count"
  )
```

This graph is left skewed showing that more properties in this data set were built more recently. There are two spikes, one around the 1980s and another in the early 2000s.

###Year Built vs. Price Range

```{r}
train |> 
  ggplot() +
  geom_bar(aes(x = yearBuilt, fill = priceRange)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Year Built", y = "Price Range", title = "Year Built vs. Price Range")
```

This graph shows that price ranges can vary over time. All years contain properties of different price ranges.

##Number of Bathrooms

```{r}
train |>
ggplot() +
  geom_bar(aes(x = numOfBathrooms, fill = numOfBathrooms)) +  # Adjust bar width
  scale_y_continuous(expand = c(0, 0)) +  # Remove extra space above bars
  theme_minimal() +  # Use a cleaner theme
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "none"  # Remove legend if not needed
  ) +
  labs(
    title = "Number of Bathrooms Distribution",
    x = "Number of Bathrooms",
    y = "Count"
  )
```

About 2500 properties have two bathrooms, approximately 2250 properties have three bathrooms, and the third most frequent number of bathrooms is four with over 750 properties.

###Number of Bathrooms vs. Price Range

```{r}
train |> 
  ggplot() +
  geom_bar(aes(x = numOfBathrooms, fill = priceRange)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Number of Bathrooms", y = "Price Range", title = "Number of Bathrooms vs. Price Range")
```

Properties with one bathroom are primarily in the bottom three price ranges. Properties with two bathrooms are mostly in the price range of 250,000 - 350,000 or 350,000 - 450,000. Properties with three bathrooms are mostly in the 450,000 - 650,000 and 650,000+ price ranges. Finally, properties with five or more bathrooms are mostly in the 650,000+ price range.

##Number of Bedrooms

```{r}
train |>
ggplot() +
  geom_bar(aes(x = numOfBedrooms, fill = numOfBedrooms)) +  # Adjust bar width
  scale_y_continuous(expand = c(0, 0)) +  # Remove extra space above bars
  theme_minimal() +  # Use a cleaner theme
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "none"  # Remove legend if not needed
  ) +
  labs(
    title = "Number of Bedrooms Distribution",
    x = "Number of Bedrooms",
    y = "Count"
  )
```

Most properties have three bedrooms with the count being over 3000. Four bedrooms is the second most frequent with over 2000 properties and all other number of bedrooms had a count of around 500 properties or less.

```{r}
train |> 
  ggplot() +
  geom_bar(aes(x = numOfBedrooms, fill = priceRange)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Number of Bedrooms", y = "Price Range", title = "Number of Bedrooms vs. Price Range")
```

Properties with two bedrooms had a fairly even numbers within the lower four price ranges and having fewer properties in the 650,000+ price range. Properties with three bedrooms were mostly in the 250,000 - 350,000 and 350,000 - 450,000 price ranges. Properties with five or more bedrooms were mostly 450,000 - 650,000 and 650,000+.

##Number of Patio and Porch Features

```{r}
train |>
  ggplot() +
  geom_bar(aes(x = numOfPatioAndPorchFeatures, fill = numOfPatioAndPorchFeatures)) +  # Adjust bar width
  scale_y_continuous(expand = c(0, 0)) +  # Remove extra space above bars
  theme_minimal() +  # Use a cleaner theme
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    legend.position = "none"  # Remove legend if not needed
  ) +
  labs(
    title = "Number of Patio and Porch Features",
    x = "Number of  Patio and Porch Features",
    y = "Count"
  )
```

This graph shows a very strong right skew showing that most of the properties do not have any porch or patio features. As the number of porch and patio features increases the count of properties decreases.

```{r}
train |> 
  ggplot() +
  geom_bar(aes(x = numOfPatioAndPorchFeatures, fill = priceRange)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Number of Patio and Porch Features", y = "Price Range", title = "Number of Patio and Porch Features vs. Price Range")
```

This graph shows that the number of porch and patio features does not affect the price range of properties that much.

##Spa

```{r}
train %>%
  ggplot() +
  geom_bar(aes(x = hasSpa))
```

The majority of properties do not have a spa.

```{r}
train |> 
  ggplot()+
  geom_bar(aes(x = hasSpa, fill = priceRange))
```

Among the properties that do not have a spa, it includes all price ranges. The majority of properties with a spa are 450,000 - 650,000 or 650,000+ yet not overwhelmingly.

##Average school rating

```{r}
train |> 
  ggplot() +
  geom_density(aes(x = avgSchoolRating, fill = "blue"))
```

This graph shows that there are peaks in average school rating at just under four and seven. There is a consistent spread of average school ratings from two to eight.

```{r}
train |> 
  ggplot() +
  geom_density(aes(x = avgSchoolRating, fill = priceRange))
```

The properties with a price range of 0 - 250,000 have a peak for average school rating around 3.5. On the other hand properties in the price range of 650,000+ have a peak at 7. In addition, the price ranges 250,000 - 350,000 and 350,000 - 450,000 are right skewed showing the majority of school ratings are lower while the price range 450,000 - 650,000 is left skewed showing most ratings are higher.

## Model Construction

First model

```{r}
log_reg_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
```

```{r}
log_reg_rec <- recipe(priceRange ~ ., data = train) %>%
  step_rm(id) %>%
  step_rm(description) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors())
```

```{r}
log_reg_wf <- workflow() %>%
  add_model(log_reg_spec) %>%
  add_recipe(log_reg_rec)
```

```{r}
log_reg_fit <- log_reg_wf %>%
  fit(train)
```

```{r}
log_reg_fit %>%
  extract_fit_engine() %>%
  tidy() %>%
  kable()
```

Code to make predictions




### Decision Tree

```{r}
dt_spec <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

dt_rec <- recipe(priceRange ~ ., data = train) %>%
  step_rm(id) %>%
  step_rm(description) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>%
  step_novel() %>%
  step_dummy(all_nominal_predictors())


dt_wf <- workflow() %>%
  add_model(dt_spec) %>%
  add_recipe(dt_rec)

dt_fit <- dt_wf %>%
  fit(train)

```

```{r}
dt_fit %>%
  extract_fit_engine() %>%
  rpart.plot::rpart.plot()
```
This decision tree models houding prices based on various features such as average school rating, number of bathrooms, latitude, longitude, and lot size. The first split occurs at an average school rating of 5.5. If the rating is less than 5.5, the homes tend to be cheaper. If the rating is above 5.5, the prices are most in the 450000 - 650000. The decision tree also shows that the location of the house strongly influences prices. Bathroom count affects prices in highly rated school areas. Finally, lot sizes matters in the higher price brackets. 

```{r}
train_folds <- vfold_cv(train, v = 10)

dt_cv_results <- dt_wf %>%
  fit_resamples(train_folds)

dt_cv_results %>%
  collect_metrics()

```

```{r}
dt_spec <- decision_tree(tree_depth = tune(),   
  cost_complexity = tune(),   
  min_n = tune()) %>%
  set_engine("rpart") %>%
  set_mode("classification")

dt_wf <- workflow() %>%
  add_model(dt_spec) %>%
  add_recipe(dt_rec)
  
  dt_tune_results <- dt_wf %>%
  tune_grid(
    resamples = train_folds,
    grid = 10
  )
  
dt_tune_results %>%
  show_best(n = 10, metric = "accuracy")

dt_tune_results <- dt_wf %>%
  tune_grid(
    resamples = train_folds
  )

dt_tune_results %>%
  show_best(n = 10, metric = "accuracy")


best_params <- dt_tune_results %>%
  select_best(metric = "accuracy")
```

```{r}
# Define a Decision Tree specification with multiple tunable hyperparameters
dt_spec <- decision_tree(
  tree_depth = tune(),        # Maximum depth of the tree
  cost_complexity = tune(),   # Complexity parameter (cp)
  min_n = tune()              # Minimum number of observations per node
) %>%
  set_engine("rpart") %>%
  set_mode("classification")

# Define a workflow
dt_wf <- workflow() %>%
  add_model(dt_spec) %>%
  add_recipe(dt_rec)

# Define a grid of hyperparameters for tuning
dt_grid <- grid_regular(
  tree_depth(range = c(1, 15)),       
  cost_complexity(range = c(0.0001, 0.1)),  
  min_n(range = c(2, 50)),             
  levels = 10  
)

# Perform tuning using cross-validation folds
dt_tune_results <- dt_wf %>%
  tune_grid(
    resamples = train_folds, 
    grid = dt_grid            
  )


dt_tune_results %>%
  show_best(n = 10, metric = "accuracy")


best_params <- dt_tune_results %>%
  select_best(metric = "accuracy")


final_dt_wf <- finalize_workflow(dt_wf, best_params)


final_dt_model <- final_dt_wf %>%
  fit(data = train)


```

```{r}
n_cores <- parallel::detectCores()
cluster <- parallel::makeCluster(n_cores - 1, type = "PSOCK")
doParallel::registerDoParallel(cluster)

tictoc::tic()

dt_tune_results <- dt_wf %>%
  tune_grid(
    resamples = train_folds,
    grid = 12,
    metrics = metric_set(accuracy,precision)
  )
```

```{r}
submission <- dt_fit %>%
  augment(Comp) %>%
  rename(
    prob_A = ".pred_0-250000",
    prob_B = ".pred_250000-350000",
    prob_C = ".pred_350000-450000",
    prob_D = ".pred_450000-650000",
    prob_E = ".pred_650000+"
  ) %>%
  select(id, starts_with ("prob"))

write.csv(submission, "submission.csv", row.names = FALSE)
```

### Nearest Neighbor

```{r}
knn_spec <- nearest_neighbor() %>%
  set_engine("kknn") %>%
  set_mode("classification")

knn_rec <- recipe(priceRange ~ ., data = train) %>%
  step_rm(id, description) %>%  
  step_novel(all_nominal_predictors()) %>%  # Handle unseen categories  
  step_dummy(all_nominal_predictors()) %>%  # Convert categorical variables to dummy
  step_impute_median(all_numeric_predictors()) %>%  
  step_impute_mode(all_nominal_predictors())


knn_spec <- nearest_neighbor(
  neighbors = tune(),  # Number of neighbors to tune
  weight_func = "rectangular",  
  dist_power = 2
) %>%
  set_engine("kknn") %>%
  set_mode("classification")

# Create a workflow
knn_wf <- workflow() %>%
  add_model(knn_spec) %>%
  add_recipe(knn_rec)

```





```{r}
set.seed(123)
train_folds1 <- vfold_cv(train, v = 10) # 10-fold cross-validation


knn_grid <- grid_regular(
  neighbors(range = c(1, 30)),  # Ensure correct range definition
  levels = 10
)

knn_tune_results <- knn_wf %>%
  tune_grid(
    resamples = train_folds1,
    grid = knn_grid
  )

knn_tune_results %>%
  show_best(n = 10, metric = "accuracy")


best_k <- knn_tune_results %>%
  select_best(metric = "accuracy")

final_knn_wf <- knn_wf %>%
  finalize_workflow(best_k)

# Fit the final model on the entire training set
knn_fit <- final_knn_wf %>%
  fit(data = train)
```
This table shows the result of tuning the k-nearest neigbors by varying the number of neighbors and evaluating the accuracy. The performance metric used is accuracy. The best accuracy is at neighbors = 20, meaning this is the optimal k value in this test.The higher k values beform best while very small and very large values lead to lower accuracy. The standard error is relatively small, meaning the accuracy estimates are stable across re samples. 

```{r}
submission <- knn_fit %>%
  augment(Comp) %>%
  rename(
    prob_A = ".pred_0-250000",
    prob_B = ".pred_250000-350000",
    prob_C = ".pred_350000-450000",
    prob_D = ".pred_450000-650000",
    prob_E = ".pred_650000+"
  ) %>%
  select(id, starts_with ("prob"))

write.csv(submission, "submission.csv", row.names = FALSE)
```


### Random Forest

```{r}
rf_tune_spec <- rand_forest(trees = tune()) %>%
  set_engine("ranger") %>%
  set_mode("classification")

rf_tune_rec <- recipe(priceRange ~ ., data = train) %>%
   step_rm(id) %>%
   step_rm(description) %>%
  step_unknown(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_other(all_nominal_predictors(), threshold = tune()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_impute_median(all_numeric_predictors()) 

rf_wf <- workflow() %>%
  add_model (rf_tune_spec) %>%
  add_recipe (rf_tune_rec)
```



## Model Interpretation and Inference

## Conclusion

## References

## 

```         
```

## 
